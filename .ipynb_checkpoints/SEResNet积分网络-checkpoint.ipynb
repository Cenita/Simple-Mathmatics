{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle as paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import PIL.Image as Image\n",
    "from paddle.fluid.initializer import MSRA\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "from visualdl import LogWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "def produce_path_label(path):\n",
    "    train_list = np.load(path)\n",
    "    return train_list\n",
    "\n",
    "def produce_test(path):\n",
    "    train_list = []\n",
    "    train_data = open(path).readlines()\n",
    "    for i in train_data:\n",
    "        items = i.split(',')\n",
    "        class_index = int(items[0])\n",
    "        img = np.array(items[1:]).astype('uint8')\n",
    "        train_list.append([class_index,img])\n",
    "    return train_list\n",
    "\n",
    "train_list = produce_path_label('data/Integral_train_list.npy')\n",
    "test_list = produce_path_label('data/Integral_test_list.npy')\n",
    "class_number = len(train_list)\n",
    "print(class_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = [64,64]\n",
    "class SE_ResNeXt():\n",
    "    def __init__(self, layers=50):\n",
    "        self.layers = layers\n",
    "\n",
    "    def net(self, input, class_dim=1000):\n",
    "        layers = self.layers\n",
    "        supported_layers = [50, 101, 152]\n",
    "        assert layers in supported_layers, \\\n",
    "            \"supported layers are {} but input layer is {}\".format(supported_layers, layers)\n",
    "        if layers == 50:\n",
    "            cardinality = 32\n",
    "            reduction_ratio = 16\n",
    "            depth = [3, 4, 6, 3]\n",
    "            num_filters = [128, 256, 512, 1024]\n",
    "\n",
    "            conv = self.conv_bn_layer(\n",
    "                input=input,\n",
    "                num_filters=64,\n",
    "                filter_size=7,\n",
    "                stride=2,\n",
    "                act='relu',\n",
    "                name='conv1', )\n",
    "            conv = fluid.layers.pool2d(\n",
    "                input=conv,\n",
    "                pool_size=3,\n",
    "                pool_stride=2,\n",
    "                pool_padding=1,\n",
    "                pool_type='max',\n",
    "                use_cudnn=False)\n",
    "        elif layers == 101:\n",
    "            cardinality = 32\n",
    "            reduction_ratio = 16\n",
    "            depth = [3, 4, 23, 3]\n",
    "            num_filters = [128, 256, 512, 1024]\n",
    "\n",
    "            conv = self.conv_bn_layer(\n",
    "                input=input,\n",
    "                num_filters=64,\n",
    "                filter_size=7,\n",
    "                stride=2,\n",
    "                act='relu',\n",
    "                name=\"conv1\", )\n",
    "            conv = fluid.layers.pool2d(\n",
    "                input=conv,\n",
    "                pool_size=3,\n",
    "                pool_stride=2,\n",
    "                pool_padding=1,\n",
    "                pool_type='max',\n",
    "                use_cudnn=False)\n",
    "        elif layers == 152:\n",
    "            cardinality = 64\n",
    "            reduction_ratio = 16\n",
    "            depth = [3, 8, 36, 3]\n",
    "            num_filters = [128, 256, 512, 1024]\n",
    "\n",
    "            conv = self.conv_bn_layer(\n",
    "                input=input,\n",
    "                num_filters=64,\n",
    "                filter_size=3,\n",
    "                stride=2,\n",
    "                act='relu',\n",
    "                name='conv1')\n",
    "            conv = self.conv_bn_layer(\n",
    "                input=conv,\n",
    "                num_filters=64,\n",
    "                filter_size=3,\n",
    "                stride=1,\n",
    "                act='relu',\n",
    "                name='conv2')\n",
    "            conv = self.conv_bn_layer(\n",
    "                input=conv,\n",
    "                num_filters=128,\n",
    "                filter_size=3,\n",
    "                stride=1,\n",
    "                act='relu',\n",
    "                name='conv3')\n",
    "            conv = fluid.layers.pool2d(\n",
    "                input=conv, pool_size=3, pool_stride=2, pool_padding=1, \\\n",
    "                pool_type='max', use_cudnn=False)\n",
    "        n = 1 if layers == 50 or layers == 101 else 3\n",
    "        for block in range(len(depth)):\n",
    "            n += 1\n",
    "            for i in range(depth[block]):\n",
    "                conv = self.bottleneck_block(\n",
    "                    input=conv,\n",
    "                    num_filters=num_filters[block],\n",
    "                    stride=2 if i == 0 and block != 0 else 1,\n",
    "                    cardinality=cardinality,\n",
    "                    reduction_ratio=reduction_ratio,\n",
    "                    name=str(n) + '_' + str(i + 1))\n",
    "\n",
    "        pool = fluid.layers.pool2d(\n",
    "            input=conv,\n",
    "            pool_size=7,\n",
    "            pool_type='avg',\n",
    "            global_pooling=True,\n",
    "            use_cudnn=False)\n",
    "        drop = fluid.layers.dropout(\n",
    "            x=pool, dropout_prob=0.5, seed=None)\n",
    "        stdv = 1.0 / math.sqrt(drop.shape[1] * 1.0)\n",
    "        out = fluid.layers.fc(\n",
    "            input=drop,\n",
    "            size=class_dim,\n",
    "            act='softmax',\n",
    "            param_attr=ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv),\n",
    "                name='fc6_weights'),\n",
    "            bias_attr=ParamAttr(name='fc6_offset'))\n",
    "        return out\n",
    "\n",
    "    def shortcut(self, input, ch_out, stride, name):\n",
    "        ch_in = input.shape[1]\n",
    "        if ch_in != ch_out or stride != 1:\n",
    "            filter_size = 1\n",
    "            return self.conv_bn_layer(\n",
    "                input, ch_out, filter_size, stride, name='conv' + name + '_prj')\n",
    "        else:\n",
    "            return input\n",
    "\n",
    "    def bottleneck_block(self,\n",
    "                         input,\n",
    "                         num_filters,\n",
    "                         stride,\n",
    "                         cardinality,\n",
    "                         reduction_ratio,\n",
    "                         name=None):\n",
    "        conv0 = self.conv_bn_layer(\n",
    "            input=input,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=1,\n",
    "            act='relu',\n",
    "            name='conv' + name + '_x1')\n",
    "        conv1 = self.conv_bn_layer(\n",
    "            input=conv0,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=3,\n",
    "            stride=stride,\n",
    "            groups=cardinality,\n",
    "            act='relu',\n",
    "            name='conv' + name + '_x2')\n",
    "        conv2 = self.conv_bn_layer(\n",
    "            input=conv1,\n",
    "            num_filters=num_filters * 2,\n",
    "            filter_size=1,\n",
    "            act=None,\n",
    "            name='conv' + name + '_x3')\n",
    "        scale = self.squeeze_excitation(\n",
    "            input=conv2,\n",
    "            num_channels=num_filters * 2,\n",
    "            reduction_ratio=reduction_ratio,\n",
    "            name='fc' + name)\n",
    "\n",
    "        short = self.shortcut(input, num_filters * 2, stride, name=name)\n",
    "\n",
    "        return fluid.layers.elementwise_add(x=short, y=scale, act='relu')\n",
    "\n",
    "    def conv_bn_layer(self,\n",
    "                      input,\n",
    "                      num_filters,\n",
    "                      filter_size,\n",
    "                      stride=1,\n",
    "                      groups=1,\n",
    "                      act=None,\n",
    "                      name=None):\n",
    "        conv = fluid.layers.conv2d(\n",
    "            input=input,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=filter_size,\n",
    "            stride=stride,\n",
    "            padding=(filter_size - 1) // 2,\n",
    "            groups=groups,\n",
    "            act=None,\n",
    "            bias_attr=False,\n",
    "            param_attr=ParamAttr(name=name + '_weights'), )\n",
    "        bn_name = name + \"_bn\"\n",
    "        return fluid.layers.batch_norm(\n",
    "            input=conv,\n",
    "            act=act,\n",
    "            param_attr=ParamAttr(name=bn_name + '_scale'),\n",
    "            bias_attr=ParamAttr(bn_name + '_offset'),\n",
    "            moving_mean_name=bn_name + '_mean',\n",
    "            moving_variance_name=bn_name + '_variance')\n",
    "\n",
    "    def squeeze_excitation(self,\n",
    "                           input,\n",
    "                           num_channels,\n",
    "                           reduction_ratio,\n",
    "                           name=None):\n",
    "        pool = fluid.layers.pool2d(\n",
    "            input=input,\n",
    "            pool_size=0,\n",
    "            pool_type='avg',\n",
    "            global_pooling=True,\n",
    "            use_cudnn=False)\n",
    "        stdv = 1.0 / math.sqrt(pool.shape[1] * 1.0)\n",
    "        squeeze = fluid.layers.fc(\n",
    "            input=pool,\n",
    "            size=num_channels // reduction_ratio,\n",
    "            act='relu',\n",
    "            param_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv),\n",
    "                name=name + '_sqz_weights'),\n",
    "            bias_attr=ParamAttr(name=name + '_sqz_offset'))\n",
    "        stdv = 1.0 / math.sqrt(squeeze.shape[1] * 1.0)\n",
    "        excitation = fluid.layers.fc(\n",
    "            input=squeeze,\n",
    "            size=num_channels,\n",
    "            act='sigmoid',\n",
    "            param_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv),\n",
    "                name=name + '_exc_weights'),\n",
    "            bias_attr=ParamAttr(name=name + '_exc_offset'))\n",
    "        scale = fluid.layers.elementwise_mul(x=input, y=excitation, axis=0)\n",
    "        return scale\n",
    "\n",
    "\n",
    "def SE_ResNeXt50_32x4d():\n",
    "    model = SE_ResNeXt(layers=50)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yuzhi = 1\n",
    "def addGaussianNoise(image): \n",
    "    G_Noiseimg = np.array(image)\n",
    "    G_NoiseNum=random.randint(1,5)\n",
    "    for i in range(G_NoiseNum): \n",
    "        temp_x = np.random.randint(0,image.shape[0])\n",
    "        temp_y = np.random.randint(0,image.shape[0])\n",
    "        temp_x_size = np.random.randint(1,5)\n",
    "        temp_y_size = np.random.randint(1,5)\n",
    "        temp_x_end = min(image.shape[0],temp_x+temp_x_size)\n",
    "        temp_y_end = min(image.shape[0],temp_y+temp_y_size)\n",
    "        for x in range(temp_x,temp_x_end):\n",
    "            for y in range(temp_y,temp_y_end):\n",
    "                G_Noiseimg[x][y] = 255\n",
    "    return G_Noiseimg\n",
    "def for_iterater_reader(t_list):\n",
    "    def reader():\n",
    "        for i in range(0,4000):\n",
    "            for label in range(0,class_number):\n",
    "              #  try:\n",
    "                    #img = cv2.resize(img,(data_shape[0],data_shape[1]))\n",
    "                    #img = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "                    #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "                    tmp_ran = train_list[label]\n",
    "                    ran_int = random.randint(0,len(tmp_ran)-1)#取随机的一个数\n",
    "                    img = np.array(tmp_ran[ran_int]).reshape(64,64)\n",
    "                    r_sofang = random.randint(6,12)/10\n",
    "                    shape = int(r_sofang*data_shape[0])\n",
    "                    img = np.array(img)\n",
    "                    _, img = cv2.threshold(img, 10, 255,cv2.THRESH_BINARY)\n",
    "                    h,w = np.array(img).shape\n",
    "                    r_x = random.randint(-5,5)\n",
    "                    r_y = random.randint(-4,4)\n",
    "                    r_rota = random.randint(-5,5)\n",
    "                    r_yh = random.randint(1,3)\n",
    "                    img = Image.fromarray(img)\n",
    "                    img = img.rotate(r_rota)\n",
    "                    tmpimg = Image.new('L',(data_shape[0],data_shape[0]))\n",
    "                    tmpimg.paste(img,(r_x,r_y))\n",
    "                    element1 = cv2.getStructuringElement(cv2.MORPH_RECT, (r_yh, r_yh))\n",
    "                    tmpimg = cv2.dilate(np.array(tmpimg), element1, iterations = 1)\n",
    "                    tmpimg = addGaussianNoise(tmpimg)\n",
    "                    #img = cv2.blur(img,(20,20))#羽化\n",
    "                    #ret, binary = cv2.threshold(img, 50, 255,cv2.THRESH_BINARY)\n",
    "                    #element1 = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))#拓展\n",
    "                    #img = cv2.erode(binary, element1, iterations = 1)\n",
    "                    img = np.array(tmpimg)\n",
    "                    ######################################################\n",
    "                    img = img.reshape(1,data_shape[0],data_shape[1]).astype('float32')\n",
    "                    img = (img)/255 \n",
    "                    yield label,img\n",
    "            #    except Exception:\n",
    "             #       print(label)\n",
    "    return reader\n",
    "\n",
    "def for_test_reader(t_list):\n",
    "    def reader():\n",
    "        for class_index in t_list:\n",
    "            image = np.array(class_index[1]).reshape(64,64)\n",
    "            image = Image.fromarray(image).resize((data_shape[0],data_shape[0]))\n",
    "            image = np.array(image).reshape(1,data_shape[0],data_shape[0]).astype('float32')\n",
    "            image = (image) / 255.0\n",
    "            yield class_index[0],image\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.设置地方\n",
    "place = fluid.CUDAPlace(0)\n",
    "#2.设置数据和设置标签\n",
    "label = fluid.layers.data(name = 'label',shape=[1],dtype='int64')\n",
    "image = fluid.layers.data(name = 'image',shape=[1,data_shape[0],data_shape[1]],dtype='float32')\n",
    "#3.设置网络和Feeder\n",
    "feeder = fluid.DataFeeder(place = place , feed_list = [label,image])\n",
    "net = SE_ResNeXt50_32x4d().net(image,class_number)\n",
    "#4.设置损失函数和正确率\n",
    "cost = fluid.layers.cross_entropy(input = net , label = label)\n",
    "avg_cost = fluid.layers.mean(cost)\n",
    "acc = fluid.layers.accuracy(input = net , label =label)\n",
    "#.定义测试程序\n",
    "test_program = fluid.default_main_program().clone(for_test=True)\n",
    "#5.设置优化\n",
    "LR = 0.001\n",
    "piecewise_decay = fluid.layers.piecewise_decay([1000,5000,10000], [LR, LR * 0.01,LR * 0.001,LR * 0.0001])\n",
    "optimizer = fluid.optimizer.AdamOptimizer(learning_rate=piecewise_decay)\n",
    "optimizer.minimize(avg_cost)\n",
    "#6.定义Executor\n",
    "exe = fluid.Executor(place = place)\n",
    "exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "def save_inference(pass_id):\n",
    "     # 保存预测模型\n",
    "    save_path = 'models/infer_model/'+str(pass_id)+\"/\"\n",
    "    # 删除旧的模型文件\n",
    "    shutil.rmtree(save_path, ignore_errors=True)\n",
    "    # 创建保持模型文件目录\n",
    "    os.makedirs(save_path)\n",
    "    # 保存预测模型\n",
    "    fluid.io.save_inference_model(save_path, feeded_var_names=[image.name], target_vars=[net], executor=exe)\n",
    "\n",
    "def save_model(pass_id):\n",
    "    # 保存参数模型\n",
    "    save_path = 'models/params_model/'+str(pass_id)+\"/\"\n",
    "    # 删除旧的模型文件\n",
    "    shutil.rmtree(save_path, ignore_errors=True)\n",
    "    # 创建保持模型文件目录\n",
    "    os.makedirs(save_path)\n",
    "    # 保存参数模型\n",
    "    fluid.io.save_params(executor=exe, dirname=save_path)\n",
    "\n",
    "def load_model(pass_id):\n",
    "    # 加载之前训练过的参数模型\n",
    "    save_path = 'models/params_model/'+str(pass_id)\n",
    "    if os.path.exists(save_path):\n",
    "        print('使用参数模型作为预训练模型')\n",
    "        fluid.io.load_params(executor=exe, dirname=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.数据分批\n",
    "train_Reader = paddle.batch(reader=paddle.reader.shuffle(for_iterater_reader(train_list),buf_size = 128*128),batch_size=64)\n",
    "test_Reader = paddle.batch(reader=paddle.reader.shuffle(for_iterater_reader(test_list),buf_size = 128*128),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载完毕\n"
     ]
    }
   ],
   "source": [
    "print(\"加载完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.训练\n",
    "step = 0\n",
    "best_model_precent = 0\n",
    "error_cout = 20\n",
    "save_model_name = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass：0, Batch：50, Cost：1.416828, Accuracy：0.557904\n",
      "Pass：0, Batch：100, Cost：0.458888, Accuracy：0.839154\n",
      "Pass：0, Batch：150, Cost：0.354486, Accuracy：0.882047\n",
      "Pass：0, Batch：200, Cost：0.250133, Accuracy：0.903493\n",
      "Pass：0, Batch：250, Cost：0.211558, Accuracy：0.918199\n",
      "Pass：0, Batch：300, Cost：0.161337, Accuracy：0.925245\n",
      "Pass：0, Batch：350, Cost：0.162968, Accuracy：0.933824\n",
      "Pass：0, Batch：400, Cost：0.141334, Accuracy：0.938725\n",
      "Pass：0, Batch：450, Cost：0.156524, Accuracy：0.931066\n",
      "Pass：0, Batch：500, Cost：0.140987, Accuracy：0.934130\n",
      "Pass：0, Batch：550, Cost：0.106820, Accuracy：0.949449\n",
      "Pass：0, Batch：600, Cost：0.121233, Accuracy：0.945772\n",
      "Pass：0, Batch：650, Cost：0.122756, Accuracy：0.943934\n",
      "Pass：0, Batch：700, Cost：0.112991, Accuracy：0.942402\n",
      "Pass：0, Batch：750, Cost：0.117789, Accuracy：0.944240\n",
      "Pass：0, Batch：800, Cost：0.096248, Accuracy：0.950674\n",
      "Pass：0, Batch：850, Cost：0.087946, Accuracy：0.954963\n",
      "Pass：0, Batch：900, Cost：0.091476, Accuracy：0.949755\n",
      "Pass：0, Batch：950, Cost：0.105174, Accuracy：0.952512\n",
      "Pass：0, Batch：1000, Cost：0.072741, Accuracy：0.958946\n",
      "Pass：0, Batch：1050, Cost：0.080925, Accuracy：0.956495\n",
      "Pass：0, Batch：1100, Cost：0.083304, Accuracy：0.958946\n",
      "Pass：0, Batch：1150, Cost：0.069788, Accuracy：0.962010\n",
      "test - Pass: 0 Cost: 0.052368126928266166 Acc: 0.9844802188552189\n",
      "new BestPrecent: 0 thie Precent: 0.9844802188552189\n",
      "Save...model...Best_precent: 0.9844802188552189\n",
      "\n",
      "Pass：1, Batch：50, Cost：0.060953, Accuracy：0.984681\n",
      "Pass：1, Batch：100, Cost：0.060708, Accuracy：0.962929\n",
      "Pass：1, Batch：150, Cost：0.072502, Accuracy：0.956801\n",
      "Pass：1, Batch：200, Cost：0.061305, Accuracy：0.961703\n",
      "Pass：1, Batch：250, Cost：0.065930, Accuracy：0.958640\n",
      "Pass：1, Batch：300, Cost：0.050221, Accuracy：0.964461\n",
      "Pass：1, Batch：350, Cost：0.046821, Accuracy：0.965993\n",
      "Pass：1, Batch：400, Cost：0.045370, Accuracy：0.969056\n",
      "Pass：1, Batch：450, Cost：0.039466, Accuracy：0.969363\n",
      "Pass：1, Batch：500, Cost：0.043270, Accuracy：0.968137\n",
      "Pass：1, Batch：550, Cost：0.038289, Accuracy：0.969363\n",
      "Pass：1, Batch：600, Cost：0.042411, Accuracy：0.967831\n",
      "Pass：1, Batch：650, Cost：0.059086, Accuracy：0.963542\n",
      "Pass：1, Batch：700, Cost：0.048052, Accuracy：0.965993\n",
      "Pass：1, Batch：750, Cost：0.048520, Accuracy：0.965074\n",
      "Pass：1, Batch：800, Cost：0.038449, Accuracy：0.969363\n",
      "Pass：1, Batch：850, Cost：0.036326, Accuracy：0.971201\n",
      "Pass：1, Batch：900, Cost：0.034273, Accuracy：0.970588\n",
      "Pass：1, Batch：950, Cost：0.040567, Accuracy：0.967831\n",
      "Pass：1, Batch：1000, Cost：0.039868, Accuracy：0.969975\n",
      "Pass：1, Batch：1050, Cost：0.033923, Accuracy：0.970895\n",
      "Pass：1, Batch：1100, Cost：0.039533, Accuracy：0.969363\n",
      "Pass：1, Batch：1150, Cost：0.039394, Accuracy：0.967831\n",
      "test - Pass: 1 Cost: 0.03217095212959167 Acc: 0.9902804082491582\n",
      "new BestPrecent: 0.9844802188552189 thie Precent: 0.9902804082491582\n",
      "Save...model...Best_precent: 0.9902804082491582\n",
      "\n",
      "Pass：2, Batch：50, Cost：0.033111, Accuracy：0.989277\n",
      "Pass：2, Batch：100, Cost：0.035380, Accuracy：0.968750\n",
      "Pass：2, Batch：150, Cost：0.036936, Accuracy：0.967831\n",
      "Pass：2, Batch：200, Cost：0.034556, Accuracy：0.969669\n",
      "Pass：2, Batch：250, Cost：0.030577, Accuracy：0.972120\n",
      "Pass：2, Batch：300, Cost：0.033315, Accuracy：0.969975\n",
      "Pass：2, Batch：350, Cost：0.038648, Accuracy：0.969056\n",
      "Pass：2, Batch：400, Cost：0.040461, Accuracy：0.967525\n",
      "Pass：2, Batch：450, Cost：0.035162, Accuracy：0.969056\n",
      "Pass：2, Batch：500, Cost：0.020774, Accuracy：0.974265\n",
      "Pass：2, Batch：550, Cost：0.031526, Accuracy：0.970895\n",
      "Pass：2, Batch：600, Cost：0.043712, Accuracy：0.969363\n",
      "Pass：2, Batch：650, Cost：0.035839, Accuracy：0.970895\n",
      "Pass：2, Batch：700, Cost：0.037116, Accuracy：0.971201\n",
      "Pass：2, Batch：750, Cost：0.027766, Accuracy：0.971507\n",
      "Pass：2, Batch：800, Cost：0.029119, Accuracy：0.970895\n",
      "Pass：2, Batch：850, Cost：0.028925, Accuracy：0.971814\n",
      "Pass：2, Batch：900, Cost：0.037388, Accuracy：0.969975\n",
      "Pass：2, Batch：950, Cost：0.023409, Accuracy：0.973039\n",
      "Pass：2, Batch：1000, Cost：0.031935, Accuracy：0.971201\n",
      "Pass：2, Batch：1050, Cost：0.022825, Accuracy：0.972733\n",
      "Pass：2, Batch：1100, Cost：0.026047, Accuracy：0.970588\n",
      "Pass：2, Batch：1150, Cost：0.040685, Accuracy：0.969975\n",
      "test - Pass: 2 Cost: 0.025055258670936047 Acc: 0.992739898989899\n",
      "new BestPrecent: 0.9902804082491582 thie Precent: 0.992739898989899\n",
      "Save...model...Best_precent: 0.992739898989899\n",
      "\n",
      "Pass：3, Batch：50, Cost：0.028592, Accuracy：0.993260\n",
      "Pass：3, Batch：100, Cost：0.023997, Accuracy：0.972426\n",
      "Pass：3, Batch：150, Cost：0.036700, Accuracy：0.969056\n",
      "Pass：3, Batch：200, Cost：0.028622, Accuracy：0.970282\n",
      "Pass：3, Batch：250, Cost：0.027450, Accuracy：0.973039\n",
      "Pass：3, Batch：300, Cost：0.026200, Accuracy：0.970895\n",
      "Pass：3, Batch：350, Cost：0.043409, Accuracy：0.969056\n",
      "Pass：3, Batch：400, Cost：0.023278, Accuracy：0.974571\n",
      "Pass：3, Batch：450, Cost：0.028804, Accuracy：0.970895\n",
      "Pass：3, Batch：500, Cost：0.037946, Accuracy：0.969669\n",
      "Pass：3, Batch：550, Cost：0.023331, Accuracy：0.973346\n",
      "Pass：3, Batch：600, Cost：0.026426, Accuracy：0.973039\n",
      "Pass：3, Batch：650, Cost：0.026362, Accuracy：0.973039\n",
      "Pass：3, Batch：700, Cost：0.029067, Accuracy：0.973346\n",
      "Pass：3, Batch：750, Cost：0.030582, Accuracy：0.970895\n",
      "Pass：3, Batch：800, Cost：0.024328, Accuracy：0.971507\n",
      "Pass：3, Batch：850, Cost：0.030038, Accuracy：0.972426\n",
      "Pass：3, Batch：900, Cost：0.029248, Accuracy：0.969669\n",
      "Pass：3, Batch：950, Cost：0.029317, Accuracy：0.972426\n",
      "Pass：3, Batch：1000, Cost：0.031907, Accuracy：0.972733\n",
      "Pass：3, Batch：1050, Cost：0.023129, Accuracy：0.972120\n",
      "Pass：3, Batch：1100, Cost：0.025109, Accuracy：0.971814\n",
      "Pass：3, Batch：1150, Cost：0.026963, Accuracy：0.971507\n",
      "test - Pass: 3 Cost: 0.02143800181402307 Acc: 0.9930687079124579\n",
      "new BestPrecent: 0.992739898989899 thie Precent: 0.9930687079124579\n",
      "Save...model...Best_precent: 0.9930687079124579\n",
      "\n",
      "Pass：4, Batch：50, Cost：0.034752, Accuracy：0.990809\n",
      "Pass：4, Batch：100, Cost：0.027343, Accuracy：0.972120\n",
      "Pass：4, Batch：150, Cost：0.020278, Accuracy：0.973958\n",
      "Pass：4, Batch：200, Cost：0.028335, Accuracy：0.973039\n",
      "Pass：4, Batch：250, Cost：0.028140, Accuracy：0.973039\n",
      "Pass：4, Batch：300, Cost：0.025709, Accuracy：0.972120\n",
      "Pass：4, Batch：350, Cost：0.020544, Accuracy：0.973958\n",
      "Pass：4, Batch：400, Cost：0.022177, Accuracy：0.974877\n",
      "Pass：4, Batch：450, Cost：0.024708, Accuracy：0.974265\n",
      "Pass：4, Batch：500, Cost：0.034198, Accuracy：0.970282\n",
      "Pass：4, Batch：550, Cost：0.020910, Accuracy：0.973652\n",
      "Pass：4, Batch：600, Cost：0.032100, Accuracy：0.971814\n",
      "Pass：4, Batch：650, Cost：0.023116, Accuracy：0.973039\n",
      "Pass：4, Batch：700, Cost：0.019607, Accuracy：0.973652\n",
      "Pass：4, Batch：750, Cost：0.029042, Accuracy：0.972120\n",
      "Pass：4, Batch：800, Cost：0.024818, Accuracy：0.972733\n",
      "Pass：4, Batch：850, Cost：0.022703, Accuracy：0.973652\n",
      "Pass：4, Batch：900, Cost：0.025588, Accuracy：0.973958\n",
      "Pass：4, Batch：950, Cost：0.031440, Accuracy：0.970588\n",
      "Pass：4, Batch：1000, Cost：0.022469, Accuracy：0.973958\n",
      "Pass：4, Batch：1050, Cost：0.024703, Accuracy：0.971814\n",
      "Pass：4, Batch：1100, Cost：0.027787, Accuracy：0.973039\n",
      "Pass：4, Batch：1150, Cost：0.029898, Accuracy：0.970282\n",
      "test - Pass: 4 Cost: 0.02120323590904389 Acc: 0.9935027356902357\n",
      "new BestPrecent: 0.9930687079124579 thie Precent: 0.9935027356902357\n",
      "Save...model...Best_precent: 0.9935027356902357\n",
      "\n",
      "Pass：5, Batch：50, Cost：0.023014, Accuracy：0.993260\n",
      "Pass：5, Batch：100, Cost：0.030495, Accuracy：0.970588\n",
      "Pass：5, Batch：150, Cost：0.030771, Accuracy：0.971201\n",
      "Pass：5, Batch：200, Cost：0.027536, Accuracy：0.972120\n",
      "Pass：5, Batch：250, Cost：0.028884, Accuracy：0.972120\n",
      "Pass：5, Batch：300, Cost：0.030736, Accuracy：0.972733\n",
      "Pass：5, Batch：350, Cost：0.022452, Accuracy：0.973346\n",
      "Pass：5, Batch：400, Cost：0.023393, Accuracy：0.973039\n",
      "Pass：5, Batch：450, Cost：0.018653, Accuracy：0.974877\n",
      "Pass：5, Batch：500, Cost：0.031317, Accuracy：0.968444\n",
      "Pass：5, Batch：550, Cost：0.017735, Accuracy：0.975184\n",
      "Pass：5, Batch：600, Cost：0.024437, Accuracy：0.973039\n",
      "Pass：5, Batch：650, Cost：0.026707, Accuracy：0.973958\n",
      "Pass：5, Batch：700, Cost：0.026189, Accuracy：0.972426\n",
      "Pass：5, Batch：750, Cost：0.025372, Accuracy：0.971201\n",
      "Pass：5, Batch：800, Cost：0.018676, Accuracy：0.973652\n",
      "Pass：5, Batch：850, Cost：0.023555, Accuracy：0.973652\n",
      "Pass：5, Batch：900, Cost：0.022931, Accuracy：0.972120\n",
      "Pass：5, Batch：950, Cost：0.021704, Accuracy：0.973652\n",
      "Pass：5, Batch：1000, Cost：0.024690, Accuracy：0.973039\n",
      "Pass：5, Batch：1050, Cost：0.015903, Accuracy：0.975797\n",
      "Pass：5, Batch：1100, Cost：0.021113, Accuracy：0.973039\n",
      "Pass：5, Batch：1150, Cost：0.021420, Accuracy：0.973958\n",
      "test - Pass: 5 Cost: 0.02043443076834696 Acc: 0.9935421927609428\n",
      "new BestPrecent: 0.9935027356902357 thie Precent: 0.9935421927609428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save...model...Best_precent: 0.9935421927609428\n",
      "\n",
      "Pass：6, Batch：50, Cost：0.031664, Accuracy：0.991422\n",
      "Pass：6, Batch：100, Cost：0.027569, Accuracy：0.972426\n",
      "Pass：6, Batch：150, Cost：0.030170, Accuracy：0.971201\n",
      "Pass：6, Batch：200, Cost：0.020786, Accuracy：0.973039\n",
      "Pass：6, Batch：250, Cost：0.027300, Accuracy：0.972120\n",
      "Pass：6, Batch：300, Cost：0.027457, Accuracy：0.970895\n",
      "Pass：6, Batch：350, Cost：0.019271, Accuracy：0.973958\n",
      "Pass：6, Batch：400, Cost：0.024028, Accuracy：0.973346\n",
      "Pass：6, Batch：450, Cost：0.021810, Accuracy：0.973958\n",
      "Pass：6, Batch：500, Cost：0.016248, Accuracy：0.976409\n",
      "Pass：6, Batch：550, Cost：0.026927, Accuracy：0.973346\n",
      "Pass：6, Batch：600, Cost：0.025151, Accuracy：0.971814\n",
      "Pass：6, Batch：650, Cost：0.025855, Accuracy：0.973652\n",
      "Pass：6, Batch：700, Cost：0.030890, Accuracy：0.971507\n",
      "Pass：6, Batch：750, Cost：0.017678, Accuracy：0.974571\n",
      "Pass：6, Batch：800, Cost：0.029299, Accuracy：0.972120\n",
      "Pass：6, Batch：850, Cost：0.021267, Accuracy：0.973652\n",
      "Pass：6, Batch：900, Cost：0.021420, Accuracy：0.972426\n",
      "Pass：6, Batch：950, Cost：0.019062, Accuracy：0.973958\n",
      "Pass：6, Batch：1000, Cost：0.026783, Accuracy：0.972426\n",
      "Pass：6, Batch：1050, Cost：0.019841, Accuracy：0.975797\n",
      "Pass：6, Batch：1100, Cost：0.021074, Accuracy：0.973346\n",
      "Pass：6, Batch：1150, Cost：0.027295, Accuracy：0.972426\n",
      "test - Pass: 6 Cost: 0.0201733390644626 Acc: 0.993844696969697\n",
      "new BestPrecent: 0.9935421927609428 thie Precent: 0.993844696969697\n",
      "Save...model...Best_precent: 0.993844696969697\n",
      "\n",
      "Pass：7, Batch：50, Cost：0.028121, Accuracy：0.991728\n",
      "Pass：7, Batch：100, Cost：0.036930, Accuracy：0.970282\n",
      "Pass：7, Batch：150, Cost：0.021884, Accuracy：0.973652\n",
      "Pass：7, Batch：200, Cost：0.029498, Accuracy：0.971507\n",
      "Pass：7, Batch：250, Cost：0.021504, Accuracy：0.973346\n",
      "Pass：7, Batch：300, Cost：0.030139, Accuracy：0.970282\n",
      "Pass：7, Batch：350, Cost：0.040177, Accuracy：0.969975\n",
      "Pass：7, Batch：400, Cost：0.022861, Accuracy：0.973346\n",
      "Pass：7, Batch：450, Cost：0.019726, Accuracy：0.973652\n",
      "Pass：7, Batch：500, Cost：0.020233, Accuracy：0.973346\n",
      "Pass：7, Batch：550, Cost：0.020543, Accuracy：0.973346\n",
      "Pass：7, Batch：600, Cost：0.034325, Accuracy：0.972120\n",
      "Pass：7, Batch：650, Cost：0.027824, Accuracy：0.972120\n",
      "Pass：7, Batch：700, Cost：0.017187, Accuracy：0.973346\n"
     ]
    }
   ],
   "source": [
    " def train():\n",
    "    for pass_id in range(20000):\n",
    "        sum_cost=0\n",
    "        sum_acc=0\n",
    "        global best_model_precent\n",
    "        for batch_id , data in enumerate(train_Reader()):\n",
    "            train_cost, train_acc = exe.run(program = fluid.default_main_program(),\n",
    "                                           feed = feeder.feed(data),\n",
    "                                            fetch_list = [avg_cost,acc]\n",
    "                                           )\n",
    "            sum_cost = sum_cost + train_cost[0]\n",
    "            sum_acc = sum_acc + train_acc[0]\n",
    "            if batch_id % 50 == 0 and batch_id != 0:\n",
    "                print('Pass：%d, Batch：%d, Cost：%f, Accuracy：%f' % (pass_id , batch_id , sum_cost/51, sum_acc/51))\n",
    "                sum_cost = 0\n",
    "                sum_acc = 0\n",
    "        test_sum_cost=0\n",
    "        test_sum_acc=0\n",
    "        test_cout = 0\n",
    "        for batch_id , data in enumerate(test_Reader()):\n",
    "            train_cost, train_acc = exe.run(program = test_program,\n",
    "                                           feed = feeder.feed(data),\n",
    "                                            fetch_list = [avg_cost,acc]\n",
    "                                           )\n",
    "            test_sum_cost = test_sum_cost + train_cost[0]\n",
    "            test_sum_acc = test_sum_acc + train_acc[0]\n",
    "            test_cout+=1\n",
    "        print(\"test - Pass:\",pass_id,\"Cost:\",test_sum_cost/test_cout,\"Acc:\",test_sum_acc/test_cout)\n",
    "        total_model_precent = (test_sum_acc/test_cout)\n",
    "        print(\"new BestPrecent:\",best_model_precent,\"thie Precent:\",total_model_precent)\n",
    "        if total_model_precent > best_model_precent:\n",
    "            best_model_precent = total_model_precent\n",
    "            save_model(save_model_name)\n",
    "            print(\"Save...model...Best_precent:\",best_model_precent)\n",
    "        print()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_inference(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_image = test_list[19][20]\n",
    "plt.figure()\n",
    "plt.imshow(test_image)\n",
    "test_image = np.array(test_image).astype('float32').reshape(1,1,64,64)/255\n",
    "result = exe.run(program = test_program,feed = {'image':test_image,'label':np.array([[1]]).astype('int64')},fetch_list = [net])\n",
    "print(np.argmax(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
