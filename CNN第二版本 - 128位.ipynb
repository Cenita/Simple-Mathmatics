{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle as paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import PIL.Image as Image\n",
    "from paddle.fluid.initializer import MSRA\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "from visualdl import LogWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = [128,128]\n",
    "\n",
    "\n",
    "class AlexNet():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def net(self, input, class_dim=1000):\n",
    "        stdv = 1.0 / math.sqrt(input.shape[1] * 5 * 5)\n",
    "        conv1 = fluid.layers.conv2d(\n",
    "            input=input,\n",
    "            num_filters=64,\n",
    "            filter_size=5,\n",
    "            stride=1,\n",
    "            padding=2,\n",
    "            groups=1,\n",
    "            act='relu',\n",
    "            bias_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)),\n",
    "            param_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)))\n",
    "        pool1 = fluid.layers.pool2d(\n",
    "            input=conv1,\n",
    "            pool_size=3,\n",
    "            pool_stride=2,\n",
    "            pool_padding=0,\n",
    "            pool_type='max')\n",
    "\n",
    "        stdv = 1.0 / math.sqrt(pool1.shape[1] * 5 * 5)\n",
    "        conv2 = fluid.layers.conv2d(\n",
    "            input=pool1,\n",
    "            num_filters=192,\n",
    "            filter_size=5,\n",
    "            stride=1,\n",
    "            padding=2,\n",
    "            groups=1,\n",
    "            act='relu',\n",
    "            bias_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)),\n",
    "            param_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)))\n",
    "        pool2 = fluid.layers.pool2d(\n",
    "            input=conv2,\n",
    "            pool_size=3,\n",
    "            pool_stride=2,\n",
    "            pool_padding=0,\n",
    "            pool_type='max')\n",
    "\n",
    "        stdv = 1.0 / math.sqrt(pool2.shape[1] * 3 * 3)\n",
    "        conv3 = fluid.layers.conv2d(\n",
    "            input=pool2,\n",
    "            num_filters=384,\n",
    "            filter_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            groups=1,\n",
    "            act='relu',\n",
    "            bias_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)),\n",
    "            param_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)))\n",
    "\n",
    "        stdv = 1.0 / math.sqrt(conv3.shape[1] * 3 * 3)\n",
    "        conv4 = fluid.layers.conv2d(\n",
    "            input=conv3,\n",
    "            num_filters=256,\n",
    "            filter_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            groups=1,\n",
    "            act='relu',\n",
    "            bias_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)),\n",
    "            param_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)))\n",
    "\n",
    "        stdv = 1.0 / math.sqrt(conv4.shape[1] * 3 * 3)\n",
    "        conv5 = fluid.layers.conv2d(\n",
    "            input=conv4,\n",
    "            num_filters=256,\n",
    "            filter_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            groups=1,\n",
    "            act='relu',\n",
    "            bias_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)),\n",
    "            param_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)))\n",
    "        pool5 = fluid.layers.pool2d(\n",
    "            input=conv5,\n",
    "            pool_size=3,\n",
    "            pool_stride=2,\n",
    "            pool_padding=0,\n",
    "            pool_type='max')\n",
    "        print(pool5)\n",
    "        drop6 = fluid.layers.dropout(x=pool5, dropout_prob=0.5)\n",
    "\n",
    "        stdv = 1.0 / math.sqrt(drop6.shape[1] * drop6.shape[2] *\n",
    "                               drop6.shape[3] * 1.0)\n",
    "        fc6 = fluid.layers.fc(\n",
    "            input=drop6,\n",
    "            size=256,\n",
    "            act='relu',\n",
    "            bias_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)),\n",
    "            param_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)))\n",
    "\n",
    "        drop7 = fluid.layers.dropout(x=fc6, dropout_prob=0.5)\n",
    "\n",
    "        stdv = 1.0 / math.sqrt(drop7.shape[1] * 1.0)\n",
    "        fc7 = fluid.layers.fc(\n",
    "            input=drop7,\n",
    "            size=128,\n",
    "            act='relu',\n",
    "            bias_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)),\n",
    "            param_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)))\n",
    "\n",
    "        stdv = 1.0 / math.sqrt(fc7.shape[1] * 1.0)\n",
    "        out = fluid.layers.fc(\n",
    "            input=fc7,\n",
    "            size=class_dim,\n",
    "            bias_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)),\n",
    "            param_attr=fluid.param_attr.ParamAttr(\n",
    "                initializer=fluid.initializer.Uniform(-stdv, stdv)),act='softmax')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yuzhi = 1\n",
    "def addGaussianNoise(image,percetage): \n",
    "    G_Noiseimg = image \n",
    "    G_NoiseNum=int(percetage*image.shape[0]*image.shape[1]) \n",
    "    for i in range(G_NoiseNum): \n",
    "        temp_x = np.random.randint(0,image.shape[0]) \n",
    "        temp_y = np.random.randint(0,image.shape[0])\n",
    "        G_Noiseimg[temp_x][temp_y] = 255\n",
    "    return G_Noiseimg\n",
    "def for_iterater_reader(t_list):\n",
    "    def reader():\n",
    "        for i in range(0,4000):\n",
    "            for label in range(0,21):\n",
    "              #  try:\n",
    "                    #img = cv2.resize(img,(data_shape[0],data_shape[1]))\n",
    "                    #img = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "                    #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "                    if label == 10:#没有10这个数\n",
    "                        continue\n",
    "                    tmp_ran = train_list[label]\n",
    "                    ran_int = random.randint(0,len(tmp_ran)-1)#取随机的一个数\n",
    "                    img = np.array(tmp_ran[ran_int]).reshape(28,28)\n",
    "                    img = Image.fromarray(img).resize((data_shape[0],data_shape[0]))\n",
    "                    img = np.array(img)\n",
    "                    _, img = cv2.threshold(img, 10, 255,cv2.THRESH_BINARY)\n",
    "                    if random.randint(0,1)==1:\n",
    "                        img = addGaussianNoise(img,random.randint(0,3)/100)\n",
    "                    r_x = random.randint(-5,5)\n",
    "                    r_y = random.randint(-5,5)\n",
    "                    r_rota = random.randint(-5,5)\n",
    "                    r_yh = random.randint(1,3)\n",
    "                    img = Image.fromarray(img)\n",
    "                    img = img.rotate(r_rota)\n",
    "                    tmpimg = Image.new('L',(data_shape[0],data_shape[0]))\n",
    "                    tmpimg.paste(img,(r_x,r_y))\n",
    "                    element1 = cv2.getStructuringElement(cv2.MORPH_RECT, (r_yh, r_yh))\n",
    "                    tmpimg = cv2.dilate(np.array(tmpimg), element1, iterations = 1)\n",
    "                    #img = cv2.blur(img,(20,20))#羽化\n",
    "                    #ret, binary = cv2.threshold(img, 50, 255,cv2.THRESH_BINARY)\n",
    "                    #element1 = cv2.getStructuringElement(cv2.MORPH_RECT, (10,10))#拓展\n",
    "                    #img = cv2.erode(binary, element1, iterations = 1)\n",
    "                    img = np.array(tmpimg)\n",
    "                    ######################################################\n",
    "                    img = img.reshape(1,data_shape[0],data_shape[1]).astype('float32')\n",
    "                    img = (img)/255 \n",
    "                    yield label,img\n",
    "            #    except Exception:\n",
    "             #       print(label)\n",
    "    return reader\n",
    "\n",
    "def for_test_reader(t_list):\n",
    "    def reader():\n",
    "        for class_index in t_list:\n",
    "            image = np.array(class_index[1]).reshape(28,28)\n",
    "            image = Image.fromarray(image).resize((data_shape[0],data_shape[0]))\n",
    "            image = np.array(image).reshape(1,data_shape[0],data_shape[0]).astype('float32')\n",
    "            image = (image) / 255.0\n",
    "            yield class_index[0],image\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"pool2d_2.tmp_0\"\n",
      "type {\n",
      "  type: LOD_TENSOR\n",
      "  lod_tensor {\n",
      "    tensor {\n",
      "      data_type: FP32\n",
      "      dims: -1\n",
      "      dims: 256\n",
      "      dims: 7\n",
      "      dims: 7\n",
      "    }\n",
      "    lod_level: 0\n",
      "  }\n",
      "}\n",
      "persistable: false\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.设置地方\n",
    "place = fluid.CUDAPlace(0)\n",
    "#2.设置数据和设置标签\n",
    "label = fluid.layers.data(name = 'label',shape=[1],dtype='int64')\n",
    "image = fluid.layers.data(name = 'image',shape=[1,data_shape[0],data_shape[1]],dtype='float32')\n",
    "#3.设置网络和Feeder\n",
    "feeder = fluid.DataFeeder(place = place , feed_list = [label,image])\n",
    "net = AlexNet().net(image,21)\n",
    "#4.设置损失函数和正确率\n",
    "cost = fluid.layers.cross_entropy(input = net , label = label)\n",
    "avg_cost = fluid.layers.mean(cost)\n",
    "acc = fluid.layers.accuracy(input = net , label =label)\n",
    "#.定义测试程序\n",
    "test_program = fluid.default_main_program().clone(for_test=True)\n",
    "#5.设置优化\n",
    "optimizer = fluid.optimizer.Adam(learning_rate=0.001)\n",
    "optimizer.minimize(avg_cost)\n",
    "#6.定义Executor\n",
    "exe = fluid.Executor(place = place)\n",
    "exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "def save_inference(pass_id):\n",
    "     # 保存预测模型\n",
    "    save_path = 'models/infer_model/'+str(pass_id)+\"/\"\n",
    "    # 删除旧的模型文件\n",
    "    shutil.rmtree(save_path, ignore_errors=True)\n",
    "    # 创建保持模型文件目录\n",
    "    os.makedirs(save_path)\n",
    "    # 保存预测模型\n",
    "    fluid.io.save_inference_model(save_path, feeded_var_names=[image.name], target_vars=[net], executor=exe)\n",
    "\n",
    "def save_model(pass_id):\n",
    "    # 保存参数模型\n",
    "    save_path = 'models/params_model/'+str(pass_id)+\"/\"\n",
    "    # 删除旧的模型文件\n",
    "    shutil.rmtree(save_path, ignore_errors=True)\n",
    "    # 创建保持模型文件目录\n",
    "    os.makedirs(save_path)\n",
    "    # 保存参数模型\n",
    "    fluid.io.save_params(executor=exe, dirname=save_path)\n",
    "\n",
    "def load_model(pass_id):\n",
    "    # 加载之前训练过的参数模型\n",
    "    save_path = 'models/params_model/'+str(pass_id)\n",
    "    if os.path.exists(save_path):\n",
    "        print('使用参数模型作为预训练模型')\n",
    "        fluid.io.load_params(executor=exe, dirname=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_path_label(path):\n",
    "    train_list = [[] * 1 for i in range(0,21)]\n",
    "    train_data = open(path).readlines()\n",
    "    for i in train_data:\n",
    "        items = i.split(',')\n",
    "        class_index = int(items[0])\n",
    "        img = np.array(items[1:]).astype('uint8')\n",
    "        train_list[class_index].append([img])\n",
    "    return train_list\n",
    "\n",
    "def produce_test(path):\n",
    "    train_list = []\n",
    "    train_data = open(path).readlines()\n",
    "    for i in train_data:\n",
    "        items = i.split(',')\n",
    "        class_index = int(items[0])\n",
    "        img = np.array(items[1:]).astype('uint8')\n",
    "        train_list.append([class_index,img])\n",
    "    return train_list\n",
    "train_list = produce_path_label('train_list.txt')\n",
    "test_list = produce_path_label('test_list.txt')\n",
    "true_test_list = produce_test('true_test_list.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.数据分批\n",
    "train_Reader = paddle.batch(reader=paddle.reader.shuffle(for_iterater_reader(train_list),buf_size = 128*128),batch_size=32)\n",
    "test_Reader = paddle.batch(reader=paddle.reader.shuffle(for_iterater_reader(test_list),buf_size = 128*128),batch_size=32)\n",
    "true_test_Reader = paddle.batch(reader=paddle.reader.shuffle(for_test_reader(true_test_list),buf_size = 128*128),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载完毕\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"加载完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.训练\n",
    "step = 0\n",
    "best_model_precent = 0\n",
    "error_cout = 20\n",
    "save_model_name = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass：0, Batch：50, Cost：2.986723, Accuracy：0.080882\n",
      "Pass：0, Batch：100, Cost：2.046915, Accuracy：0.329657\n",
      "Pass：0, Batch：150, Cost：1.362880, Accuracy：0.541667\n",
      "Pass：0, Batch：200, Cost：1.024309, Accuracy：0.656863\n",
      "Pass：0, Batch：250, Cost：0.855256, Accuracy：0.704657\n",
      "Pass：0, Batch：300, Cost：0.814348, Accuracy：0.712010\n",
      "Pass：0, Batch：350, Cost：0.611622, Accuracy：0.784314\n",
      "Pass：0, Batch：400, Cost：0.572955, Accuracy：0.804534\n",
      "Pass：0, Batch：450, Cost：0.521891, Accuracy：0.816789\n",
      "Pass：0, Batch：500, Cost：0.422741, Accuracy：0.843137\n",
      "Pass：0, Batch：550, Cost：0.468103, Accuracy：0.848039\n",
      "Pass：0, Batch：600, Cost：0.428219, Accuracy：0.846201\n",
      "Pass：0, Batch：650, Cost：0.379398, Accuracy：0.861520\n",
      "Pass：0, Batch：700, Cost：0.391719, Accuracy：0.860907\n",
      "Pass：0, Batch：750, Cost：0.353188, Accuracy：0.869485\n",
      "Pass：0, Batch：800, Cost：0.358046, Accuracy：0.870098\n",
      "Pass：0, Batch：850, Cost：0.361862, Accuracy：0.871324\n",
      "Pass：0, Batch：900, Cost：0.331138, Accuracy：0.882966\n",
      "Pass：0, Batch：950, Cost：0.339027, Accuracy：0.882966\n",
      "Pass：0, Batch：1000, Cost：0.260448, Accuracy：0.898284\n",
      "Pass：0, Batch：1050, Cost：0.323294, Accuracy：0.881127\n",
      "Pass：0, Batch：1100, Cost：0.229097, Accuracy：0.904412\n",
      "Pass：0, Batch：1150, Cost：0.244579, Accuracy：0.901348\n",
      "Pass：0, Batch：1200, Cost：0.294978, Accuracy：0.898284\n",
      "Pass：0, Batch：1250, Cost：0.268545, Accuracy：0.903186\n",
      "Pass：0, Batch：1300, Cost：0.208971, Accuracy：0.920343\n",
      "Pass：0, Batch：1350, Cost：0.258393, Accuracy：0.900735\n",
      "Pass：0, Batch：1400, Cost：0.230025, Accuracy：0.909314\n",
      "Pass：0, Batch：1450, Cost：0.232578, Accuracy：0.912990\n",
      "Pass：0, Batch：1500, Cost：0.196539, Accuracy：0.919730\n",
      "Pass：0, Batch：1550, Cost：0.210320, Accuracy：0.914828\n",
      "Pass：0, Batch：1600, Cost：0.219176, Accuracy：0.921569\n",
      "Pass：0, Batch：1650, Cost：0.181364, Accuracy：0.925858\n",
      "Pass：0, Batch：1700, Cost：0.153588, Accuracy：0.933211\n",
      "Pass：0, Batch：1750, Cost：0.222298, Accuracy：0.919730\n",
      "Pass：0, Batch：1800, Cost：0.185874, Accuracy：0.924020\n",
      "Pass：0, Batch：1850, Cost：0.163248, Accuracy：0.935049\n",
      "Pass：0, Batch：1900, Cost：0.177673, Accuracy：0.933211\n",
      "Pass：0, Batch：1950, Cost：0.196237, Accuracy：0.918505\n",
      "Pass：0, Batch：2000, Cost：0.191731, Accuracy：0.924632\n",
      "Pass：0, Batch：2050, Cost：0.210320, Accuracy：0.914828\n",
      "Pass：0, Batch：2100, Cost：0.166338, Accuracy：0.930760\n",
      "Pass：0, Batch：2150, Cost：0.183478, Accuracy：0.925245\n",
      "Pass：0, Batch：2200, Cost：0.158700, Accuracy：0.936887\n",
      "Pass：0, Batch：2250, Cost：0.218782, Accuracy：0.917892\n",
      "Pass：0, Batch：2300, Cost：0.145143, Accuracy：0.939338\n",
      "Pass：0, Batch：2350, Cost：0.171266, Accuracy：0.935049\n",
      "Pass：0, Batch：2400, Cost：0.180632, Accuracy：0.930147\n",
      "Pass：0, Batch：2450, Cost：0.173050, Accuracy：0.928922\n",
      "test - Pass: 0 Cost: 0.06188728230736451 Acc: 0.981275\n",
      "true test - Pass: 0 Cost: 0.8791825522979101 Acc: 0.8411458333333334\n",
      "new BestPrecent: 0 thie Precent: 0.981275\n",
      "Save...model...Best_precent: 0.981275\n",
      "\n",
      "Pass：1, Batch：50, Cost：0.196200, Accuracy：0.949142\n",
      "Pass：1, Batch：100, Cost：0.178358, Accuracy：0.932598\n",
      "Pass：1, Batch：150, Cost：0.186619, Accuracy：0.926471\n",
      "Pass：1, Batch：200, Cost：0.143823, Accuracy：0.933824\n",
      "Pass：1, Batch：250, Cost：0.183908, Accuracy：0.926471\n",
      "Pass：1, Batch：300, Cost：0.142415, Accuracy：0.935049\n",
      "Pass：1, Batch：350, Cost：0.147809, Accuracy：0.932598\n",
      "Pass：1, Batch：400, Cost：0.174018, Accuracy：0.930760\n",
      "Pass：1, Batch：450, Cost：0.157655, Accuracy：0.937500\n",
      "Pass：1, Batch：500, Cost：0.147358, Accuracy：0.937500\n",
      "Pass：1, Batch：550, Cost：0.148220, Accuracy：0.933824\n",
      "Pass：1, Batch：600, Cost：0.124407, Accuracy：0.937500\n",
      "Pass：1, Batch：650, Cost：0.145428, Accuracy：0.936275\n",
      "Pass：1, Batch：700, Cost：0.125589, Accuracy：0.941176\n",
      "Pass：1, Batch：750, Cost：0.140916, Accuracy：0.935662\n",
      "Pass：1, Batch：800, Cost：0.140758, Accuracy：0.935662\n",
      "Pass：1, Batch：850, Cost：0.157585, Accuracy：0.932598\n",
      "Pass：1, Batch：900, Cost：0.143298, Accuracy：0.933211\n",
      "Pass：1, Batch：950, Cost：0.165269, Accuracy：0.932598\n",
      "Pass：1, Batch：1000, Cost：0.138262, Accuracy：0.939951\n",
      "Pass：1, Batch：1050, Cost：0.161012, Accuracy：0.932598\n",
      "Pass：1, Batch：1100, Cost：0.147656, Accuracy：0.939338\n",
      "Pass：1, Batch：1150, Cost：0.155449, Accuracy：0.937500\n",
      "Pass：1, Batch：1200, Cost：0.129344, Accuracy：0.943015\n",
      "Pass：1, Batch：1250, Cost：0.121019, Accuracy：0.943627\n",
      "Pass：1, Batch：1300, Cost：0.124710, Accuracy：0.939951\n",
      "Pass：1, Batch：1350, Cost：0.144709, Accuracy：0.944240\n",
      "Pass：1, Batch：1400, Cost：0.154454, Accuracy：0.932598\n",
      "Pass：1, Batch：1450, Cost：0.149869, Accuracy：0.938113\n",
      "Pass：1, Batch：1500, Cost：0.136254, Accuracy：0.942402\n",
      "Pass：1, Batch：1550, Cost：0.154806, Accuracy：0.939951\n",
      "Pass：1, Batch：1600, Cost：0.128176, Accuracy：0.941176\n",
      "Pass：1, Batch：1650, Cost：0.123644, Accuracy：0.942402\n",
      "Pass：1, Batch：1700, Cost：0.136819, Accuracy：0.941176\n",
      "Pass：1, Batch：1750, Cost：0.126187, Accuracy：0.939951\n",
      "Pass：1, Batch：1800, Cost：0.126719, Accuracy：0.943627\n",
      "Pass：1, Batch：1850, Cost：0.097744, Accuracy：0.949142\n",
      "Pass：1, Batch：1900, Cost：0.115178, Accuracy：0.947917\n",
      "Pass：1, Batch：1950, Cost：0.105324, Accuracy：0.954044\n",
      "Pass：1, Batch：2000, Cost：0.135584, Accuracy：0.935662\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-479a2392ba6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m            \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Save...model...Best_precent:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbest_model_precent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-479a2392ba6b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m        \u001b[0msum_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m        \u001b[1;32mglobal\u001b[0m \u001b[0mbest_model_precent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m        \u001b[1;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_Reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m            train_cost, train_acc = exe.run(program = fluid.default_main_program(),\n\u001b[0;32m      8\u001b[0m                                           \u001b[0mfeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeeder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python3.6\\lib\\site-packages\\paddle\\batch.py\u001b[0m in \u001b[0;36mbatch_reader\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python3.6\\lib\\site-packages\\paddle\\reader\\decorator.py\u001b[0m in \u001b[0;36mdata_reader\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdata_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mbuf_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5111553240a8>\u001b[0m in \u001b[0;36mreader\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m                     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maddGaussianNoise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " def train():\n",
    "    for pass_id in range(20000):\n",
    "        sum_cost=0\n",
    "        sum_acc=0\n",
    "        global best_model_precent\n",
    "        for batch_id , data in enumerate(train_Reader()):\n",
    "            train_cost, train_acc = exe.run(program = fluid.default_main_program(),\n",
    "                                           feed = feeder.feed(data),\n",
    "                                            fetch_list = [avg_cost,acc]\n",
    "                                           )\n",
    "            sum_cost = sum_cost + train_cost[0]\n",
    "            sum_acc = sum_acc + train_acc[0]\n",
    "            if batch_id % 50 == 0 and batch_id != 0:\n",
    "                print('Pass：%d, Batch：%d, Cost：%f, Accuracy：%f' % (pass_id , batch_id , sum_cost/51, sum_acc/51))\n",
    "                sum_cost = 0\n",
    "                sum_acc = 0\n",
    "        \n",
    "        test_sum_cost=0\n",
    "        test_sum_acc=0\n",
    "        test_cout = 0\n",
    "        for batch_id , data in enumerate(test_Reader()):\n",
    "            train_cost, train_acc = exe.run(program = test_program,\n",
    "                                           feed = feeder.feed(data),\n",
    "                                            fetch_list = [avg_cost,acc]\n",
    "                                           )\n",
    "            test_sum_cost = test_sum_cost + train_cost[0]\n",
    "            test_sum_acc = test_sum_acc + train_acc[0]\n",
    "            test_cout+=1\n",
    "        print(\"test - Pass:\",pass_id,\"Cost:\",test_sum_cost/test_cout,\"Acc:\",test_sum_acc/test_cout)\n",
    "        true_sum_cost=0\n",
    "        true_sum_acc=0\n",
    "        true_cout = 0\n",
    "        for batch_id , data in enumerate(true_test_Reader()):\n",
    "            train_cost, train_acc = exe.run(program = test_program,\n",
    "                                           feed = feeder.feed(data),\n",
    "                                            fetch_list = [avg_cost,acc]\n",
    "                                           )\n",
    "            true_sum_cost = true_sum_cost + train_cost[0]\n",
    "            true_sum_acc = true_sum_acc + train_acc[0]\n",
    "            true_cout+=1\n",
    "        print(\"true test - Pass:\",pass_id,\"Cost:\",true_sum_cost/true_cout,\"Acc:\",true_sum_acc/true_cout)\n",
    "        total_model_precent = (test_sum_acc/test_cout)\n",
    "        print(\"new BestPrecent:\",best_model_precent,\"thie Precent:\",total_model_precent)\n",
    "        if total_model_precent > best_model_precent:\n",
    "            best_model_precent = total_model_precent\n",
    "            save_model(save_model_name)\n",
    "            print(\"Save...model...Best_precent:\",best_model_precent)\n",
    "        print()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_inference(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
